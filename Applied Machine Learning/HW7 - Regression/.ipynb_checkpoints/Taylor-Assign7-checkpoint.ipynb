{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7848afd4",
   "metadata": {},
   "source": [
    "#### Andrew Taylor\n",
    "#### atayl136\n",
    "#### EN705.601 Applied Machine Learning\n",
    "### Homework 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbcc8792",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "suicides_no\n",
      "population\n",
      "suicides/100k pop\n",
      "gdp_per_capita ($)\n",
      "gdp_for_year ($)\n",
      "country_Albania\n",
      "country_Antigua and Barbuda\n",
      "country_Argentina\n",
      "country_Armenia\n",
      "country_Aruba\n",
      "country_Australia\n",
      "country_Austria\n",
      "country_Azerbaijan\n",
      "country_Bahamas\n",
      "country_Bahrain\n",
      "country_Barbados\n",
      "country_Belarus\n",
      "country_Belgium\n",
      "country_Belize\n",
      "country_Bosnia and Herzegovina\n",
      "country_Brazil\n",
      "country_Bulgaria\n",
      "country_Cabo Verde\n",
      "country_Canada\n",
      "country_Chile\n",
      "country_Colombia\n",
      "country_Costa Rica\n",
      "country_Croatia\n",
      "country_Cuba\n",
      "country_Cyprus\n",
      "country_Czech Republic\n",
      "country_Denmark\n",
      "country_Dominica\n",
      "country_Ecuador\n",
      "country_El Salvador\n",
      "country_Estonia\n",
      "country_Fiji\n",
      "country_Finland\n",
      "country_France\n",
      "country_Georgia\n",
      "country_Germany\n",
      "country_Greece\n",
      "country_Grenada\n",
      "country_Guatemala\n",
      "country_Guyana\n",
      "country_Hungary\n",
      "country_Iceland\n",
      "country_Ireland\n",
      "country_Israel\n",
      "country_Italy\n",
      "country_Jamaica\n",
      "country_Japan\n",
      "country_Kazakhstan\n",
      "country_Kiribati\n",
      "country_Kuwait\n",
      "country_Kyrgyzstan\n",
      "country_Latvia\n",
      "country_Lithuania\n",
      "country_Luxembourg\n",
      "country_Macau\n",
      "country_Maldives\n",
      "country_Malta\n",
      "country_Mauritius\n",
      "country_Mexico\n",
      "country_Mongolia\n",
      "country_Montenegro\n",
      "country_Netherlands\n",
      "country_New Zealand\n",
      "country_Nicaragua\n",
      "country_Norway\n",
      "country_Oman\n",
      "country_Panama\n",
      "country_Paraguay\n",
      "country_Philippines\n",
      "country_Poland\n",
      "country_Portugal\n",
      "country_Puerto Rico\n",
      "country_Qatar\n",
      "country_Republic of Korea\n",
      "country_Romania\n",
      "country_Russian Federation\n",
      "country_Saint Kitts and Nevis\n",
      "country_Saint Lucia\n",
      "country_Saint Vincent and Grenadines\n",
      "country_San Marino\n",
      "country_Serbia\n",
      "country_Seychelles\n",
      "country_Singapore\n",
      "country_Slovakia\n",
      "country_Slovenia\n",
      "country_South Africa\n",
      "country_Spain\n",
      "country_Sri Lanka\n",
      "country_Suriname\n",
      "country_Sweden\n",
      "country_Switzerland\n",
      "country_Thailand\n",
      "country_Trinidad and Tobago\n",
      "country_Turkey\n",
      "country_Turkmenistan\n",
      "country_Ukraine\n",
      "country_United Arab Emirates\n",
      "country_United Kingdom\n",
      "country_United States\n",
      "country_Uruguay\n",
      "country_Uzbekistan\n",
      "age_15-24 years\n",
      "age_25-34 years\n",
      "age_35-54 years\n",
      "age_5-14 years\n",
      "age_55-74 years\n",
      "age_75+ years\n",
      "sex_female\n",
      "sex_male\n",
      "generation_Boomers\n",
      "generation_G.I. Generation\n",
      "generation_Generation X\n",
      "generation_Generation Z\n",
      "generation_Millenials\n",
      "generation_Silent\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing Suicide Rates Data Set\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Step 0: Load the data\n",
    "file_path = 'master.csv'  # Replace with the actual path to the dataset\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Clean column names by removing extra quotes and trimming spaces\n",
    "data.columns = data.columns.str.strip(\"' \").str.replace(\"'\", \"\")\n",
    "\n",
    "# Step 1: Handle missing values\n",
    "# Identify columns with missing values and impute them\n",
    "num_imputer = SimpleImputer(strategy='mean')\n",
    "nom_imputer = SimpleImputer(strategy='most_frequent')\n",
    "\n",
    "# Identify numerical and nominal columns, exclude the columns 'country-year', 'year', and 'HDI for year' \\\n",
    "# as redundant or incomplete.\n",
    "num_cols = ['suicides_no', 'population', 'suicides/100k pop', 'gdp_per_capita ($)']\n",
    "nom_cols = ['country', 'age', 'sex', 'generation']\n",
    "\n",
    "# Create separate imputers for numerical and nominal columns\n",
    "imputers = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_imputer, num_cols),\n",
    "        ('nom', nom_imputer, nom_cols)])\n",
    "\n",
    "# Apply imputers\n",
    "data_imputed = pd.DataFrame(imputers.fit_transform(data), columns=num_cols+nom_cols)\n",
    "data_imputed[num_cols] = data_imputed[num_cols].apply(pd.to_numeric)\n",
    "\n",
    "# Step 2: One-hot encode nominal variables\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "\n",
    "# Step 3: Normalize numerical features\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Step 4: Convert 'gdp_for_year ($)' to a proper numerical format\n",
    "data_imputed['gdp_for_year ($)'] = data['gdp_for_year ($)'].str.replace(',', '').astype(float)\n",
    "num_cols.append('gdp_for_year ($)')\n",
    "\n",
    "# Create the preprocessing pipeline\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', scaler, num_cols),\n",
    "        ('nom', one_hot_encoder, nom_cols)\n",
    "    ])\n",
    "\n",
    "# Apply the preprocessing pipeline to the data\n",
    "data_preprocessed = preprocessor.fit_transform(data_imputed)\n",
    "\n",
    "# Retrieve feature names for one-hot encoded columns\n",
    "one_hot_feature_names = preprocessor.named_transformers_['nom'].get_feature_names_out(input_features=nom_cols)\n",
    "\n",
    "# Combine all feature names\n",
    "all_feature_names = num_cols + one_hot_feature_names.tolist()\n",
    "\n",
    "# Convert the preprocessed data back to a DataFrame for better readability\n",
    "data_preprocessed_df = pd.DataFrame(data_preprocessed, columns=all_feature_names)\n",
    "\n",
    "for column in data_preprocessed_df.columns:\n",
    "    print(column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31af456a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.45562008581673424, MSE: 0.47913577061013685, R2: 0.5070618631789722\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Multiple Linear Regression Model with all features\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "# Data Preparation: Separate the target variable ('suicides/100k pop') and feature variables\n",
    "X = data_preprocessed_df.drop('suicides/100k pop', axis=1)\n",
    "y = data_preprocessed_df['suicides/100k pop']\n",
    "\n",
    "# Data Splitting: Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Select all features\n",
    "selected_features = [\n",
    "    'population', 'gdp_per_capita ($)', 'gdp_for_year ($)',\n",
    "    'country_Antigua and Barbuda', 'country_Argentina', 'country_Armenia', 'country_Aruba', 'country_Australia',\n",
    "    'country_Austria', 'country_Azerbaijan', 'country_Bahamas', 'country_Bahrain', 'country_Barbados',\n",
    "    'country_Belarus', 'country_Belgium', 'country_Belize', 'country_Bosnia and Herzegovina', 'country_Brazil',\n",
    "    'country_Bulgaria', 'country_Cabo Verde', 'country_Canada', 'country_Chile', 'country_Colombia',\n",
    "    'country_Costa Rica', 'country_Croatia', 'country_Cuba', 'country_Cyprus', 'country_Czech Republic',\n",
    "    'country_Denmark', 'country_Dominica', 'country_Ecuador', 'country_El Salvador', 'country_Estonia',\n",
    "    'country_Fiji', 'country_Finland', 'country_France', 'country_Georgia', 'country_Germany', 'country_Greece',\n",
    "    'country_Grenada', 'country_Guatemala', 'country_Guyana', 'country_Hungary', 'country_Iceland',\n",
    "    'country_Ireland', 'country_Israel', 'country_Italy', 'country_Jamaica', 'country_Japan',\n",
    "    'country_Kazakhstan', 'country_Kiribati', 'country_Kuwait', 'country_Kyrgyzstan', 'country_Latvia',\n",
    "    'country_Lithuania', 'country_Luxembourg', 'country_Macau', 'country_Maldives', 'country_Malta',\n",
    "    'country_Mauritius', 'country_Mexico', 'country_Mongolia', 'country_Montenegro', 'country_Netherlands',\n",
    "    'country_New Zealand', 'country_Nicaragua', 'country_Norway', 'country_Oman', 'country_Panama',\n",
    "    'country_Paraguay', 'country_Philippines', 'country_Poland', 'country_Portugal', 'country_Puerto Rico',\n",
    "    'country_Qatar', 'country_Republic of Korea', 'country_Romania', 'country_Russian Federation',\n",
    "    'country_Saint Kitts and Nevis', 'country_Saint Lucia', 'country_Saint Vincent and Grenadines',\n",
    "    'country_San Marino', 'country_Serbia', 'country_Seychelles', 'country_Singapore', 'country_Slovakia',\n",
    "    'country_Slovenia', 'country_South Africa', 'country_Spain', 'country_Sri Lanka', 'country_Suriname',\n",
    "    'country_Sweden', 'country_Switzerland', 'country_Thailand', 'country_Trinidad and Tobago',\n",
    "    'country_Turkey', 'country_Turkmenistan', 'country_Ukraine', 'country_United Arab Emirates',\n",
    "    'country_United Kingdom', 'country_United States', 'country_Uruguay', 'country_Uzbekistan', 'age_15-24 years',\n",
    "    'age_25-34 years', 'age_35-54 years', 'age_5-14 years', 'age_55-74 years', 'age_75+ years',\n",
    "    'sex_male',\n",
    "    'generation_G.I. Generation', 'generation_Generation X', 'generation_Generation Z',\n",
    "    'generation_Millenials', 'generation_Silent'\n",
    "]\n",
    "\n",
    "# X_train, X_test, y_train, y_test are defined and data_preprocessed_df contains the preprocessed data\n",
    "# we only consider the selected features here\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# 3. Model Building: Create the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 4. Model Training: Fit the model on the training data\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# 5. Model Evaluation: Evaluate the model using the test data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3822b08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 0.5289259937943444, MSE: 0.6883311112973017, R2: 0.29184027507116583\n"
     ]
    }
   ],
   "source": [
    "# Question 1: one hot encoded only model\n",
    "\n",
    "selected_features = [\n",
    "    'age_15-24 years', 'age_25-34 years', 'age_35-54 years', 'age_5-14 years', 'age_55-74 years', 'age_75+ years',\n",
    "    'sex_male',\n",
    "    'generation_G.I. Generation', 'generation_Generation X', 'generation_Generation Z',\n",
    "    'generation_Millenials', 'generation_Silent'\n",
    "]\n",
    "\n",
    "# X_train, X_test, y_train, y_test are defined and data_preprocessed_df contains the preprocessed data\n",
    "# we only consider the selected features here\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# 3. Model Building: Create the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 4. Model Training: Fit the model on the training data\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# 5. Model Evaluation: Evaluate the model using the test data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7492559a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Input Vector: [[1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 0. 0.]] \n",
      "\n",
      "\n",
      "\n",
      "MAE: 0.5289259937943444, MSE: 0.6883311112973017, R2: 0.29184027507116583\n",
      "Predicted Suicide Rate for Age 25, Male, Generation x: [0.22070312]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Putna\\anaconda3\\envs\\en685621\\lib\\site-packages\\sklearn\\base.py:450: UserWarning: X does not have valid feature names, but LinearRegression was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Question 1: Use one-hot encoded features only to predict age 20, male, generation X input\n",
    "# age changed to 25 because there is no data for age 20\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Initialize an input vector with zeros\n",
    "input_vector = np.zeros((1, len(selected_features)))\n",
    "\n",
    "# Filter out the features present in the dataframe\n",
    "feature_to_reset = [feature for feature in selected_features if feature in selected_features]\n",
    "\n",
    "# Reset the corresponding positions in the input vector to zero\n",
    "for feature in feature_to_reset:\n",
    "    input_vector[0][selected_features.index(feature)] = 0\n",
    "        \n",
    "# Update the values based on the given input\n",
    "input_vector[0][selected_features.index('age_15-24 years')] = 1\n",
    "input_vector[0][selected_features.index('sex_male')] = 1\n",
    "input_vector[0][selected_features.index('generation_Generation X')] = 1\n",
    "\n",
    "# Display the updated input vector\n",
    "print(f'\\nInput Vector: {input_vector} \\n')\n",
    "print('\\n')\n",
    "\n",
    "# X_train, X_test, y_train, y_test are defined and data_preprocessed_df contains the preprocessed data\n",
    "# we only consider the selected one hot features here\n",
    "X_train_selected = X_train[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n",
    "\n",
    "# 3. Model Building: Create the LinearRegression model\n",
    "model = LinearRegression()\n",
    "\n",
    "# 4. Model Training: Fit the model on the training data\n",
    "model.fit(X_train_selected, y_train)\n",
    "\n",
    "# 5. Model Evaluation: Evaluate the model using the test data\n",
    "y_pred = model.predict(X_test_selected)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"MAE: {mae}, MSE: {mse}, R2: {r2}\")\n",
    "\n",
    "\n",
    "# Use the model to make a prediction\n",
    "predicted_suicide_rate = model.predict(input_vector)\n",
    "\n",
    "print(f'Predicted Suicide Rate for Age 25, Male, Generation x: {predicted_suicide_rate}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb1a08f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Retrieve the number of regression coefficients from the model trained on the feature set\n",
    "num_coefficients = len(model.coef_)\n",
    "\n",
    "num_coefficients\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1e77006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation Metrics (Entire Dataset)\n",
      "- Mean Absolute Error (MAE): 10.17\n",
      "- Mean Squared Error (MSE): 250.64\n",
      "- Coefficient of Determination (R^2): 0.283\n",
      "\n",
      "Specific Prediction\n",
      "- Predicted Suicide Rate for Age 12-24, Male, Generation X: 14.36 per 100,000 population\n"
     ]
    }
   ],
   "source": [
    "# Question 2: Predicting the same point with Numerical and ordinal features\n",
    "\n",
    "# Define the mapping for age and generation features\n",
    "age_mapping = {\n",
    "    '5-14 years': 0,\n",
    "    '15-24 years': 1,\n",
    "    '25-34 years': 2,\n",
    "    '35-54 years': 3,\n",
    "    '55-74 years': 4,\n",
    "    '75+ years': 5\n",
    "}\n",
    "\n",
    "generation_mapping = {\n",
    "    'G.I. Generation': 0,\n",
    "    'Silent': 1,\n",
    "    'Boomers': 2,\n",
    "    'Generation X': 3,\n",
    "    'Millenials': 4,\n",
    "    'Generation Z': 5\n",
    "}\n",
    "\n",
    "# Apply the mapping to the entire dataset\n",
    "data['age_encoded'] = data['age'].map(age_mapping)\n",
    "data['generation_encoded'] = data['generation'].map(generation_mapping)\n",
    "\n",
    "# binary encode the 'sex' feature for the entire dataset\n",
    "data['sex_encoded'] = (data['sex'] == 'male').astype(int)\n",
    "\n",
    "# Extract the features and target variable from the entire dataset\n",
    "X_all = data[['age_encoded', 'sex_encoded', 'generation_encoded']].values\n",
    "y_all = data['suicides/100k pop'].values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train_all, X_test_all, y_train_all, y_test_all = train_test_split(X_all, y_all, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the Linear Regression model and fit it on the entire dataset\n",
    "model_all = LinearRegression()\n",
    "model_all.fit(X_train_all, y_train_all)\n",
    "\n",
    "# Evaluate the model using the test data from the entire dataset\n",
    "y_pred_all = model_all.predict(X_test_all)\n",
    "mae_all = mean_absolute_error(y_test_all, y_pred_all)\n",
    "mse_all = mean_squared_error(y_test_all, y_pred_all)\n",
    "r2_all = r2_score(y_test_all, y_pred_all)\n",
    "\n",
    "# Specific prediction for age 25-34 years, male, and Generation X\n",
    "# 'age_encoded' = 1, 'sex_encoded' = 1, 'generation_encoded' = 3\n",
    "specific_data_point_all = np.array([[1, 1, 3]])\n",
    "specific_prediction_all = model_all.predict(specific_data_point_all)\n",
    "\n",
    "# print the model evaluation metrics and specific prediction\n",
    "print(\"Model Evaluation Metrics (Entire Dataset)\")\n",
    "print(f\"- Mean Absolute Error (MAE): {mae_all:.2f}\")\n",
    "print(f\"- Mean Squared Error (MSE): {mse_all:.2f}\")\n",
    "print(f\"- Coefficient of Determination (R^2): {r2_all:.3f}\")\n",
    "\n",
    "print(\"\\nSpecific Prediction\")\n",
    "print(f\"- Predicted Suicide Rate for Age 12-24, Male, Generation X: {specific_prediction_all[0]:.2f} per 100,000 population\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "caddcb02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of line coefficients in the model is: 3\n"
     ]
    }
   ],
   "source": [
    "# Retrieve the number of coefficients in the linear regression model\n",
    "num_coefficients = len(model_all.coef_)\n",
    "\n",
    "print(f\"The number of line coefficients in the model is: {num_coefficients}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aad6c4db",
   "metadata": {},
   "source": [
    "#### Question 3: Performance\n",
    "\n",
    "The model with all features had these statistics:\n",
    "\n",
    "MAE: 0.45562008581673424, MSE: 0.47913577061013685, R2: 0.5070618631789722\n",
    "\n",
    "The model with the selected one-hot encoded features only had this performance for the given input on 12 coefficients:\n",
    "\n",
    "MAE: 0.5289259937943444, MSE: 0.6883311112973017, R2: 0.29184027507116583\n",
    "Predicted Suicide Rate for Age 25, Male, Generation x: [0.22070312]\n",
    "\n",
    "But the model using sex, age, and generational variables as binary and ordinal numeric features, had 3 coefficients, made a prediction for age 25, male, and generation X:\n",
    "\n",
    "Model Evaluation Metrics (Entire Dataset)\n",
    "- Mean Absolute Error (MAE): 10.17\n",
    "- Mean Squared Error (MSE): 250.64\n",
    "- Coefficient of Determination (R^2): 0.283\n",
    "\n",
    "Specific Prediction\n",
    "- Predicted Suicide Rate for Age 12-24, Male, Generation X: 14.36 per 100,000 populationModel Evaluation Metrics (Entire Dataset)\n",
    "- Mean Absolute Error (MAE): 10.17\n",
    "- Mean Squared Error (MSE): 250.64\n",
    "- Coefficient of Determination (R^2): 0.283\n",
    "\n",
    "Specific Prediction\n",
    "- Predicted Suicide Rate for Age 25-34, Male, Generation X: 18.12 per 100,000 population\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8937e037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Suicide Rate for Age 33, Male, Generation Alpha: 16.91 per 100,000 population\n"
     ]
    }
   ],
   "source": [
    "# Question 4: Prediction for age 33, male and Generation Alpha\n",
    "\n",
    "# Encoding for age 33 falls under the category '25-34 years', which is encoded as 2\n",
    "# Encoding for male is 1\n",
    "# Encoding for generation Alpha would be the generation after Generation Z, so it would be encoded as 6 (one more than Generation Z's encoding of 5)\n",
    "new_data_point = np.array([[2, 1, 6]])\n",
    "\n",
    "# Use the model to make a new prediction\n",
    "new_prediction = model_all.predict(new_data_point)\n",
    "\n",
    "print(f\"Predicted Suicide Rate for Age 33, Male, Generation Alpha: {new_prediction[0]:.2f} per 100,000 population\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9beb3179",
   "metadata": {},
   "source": [
    "#### Question 5: Advantages using Regression in terms of independent variables\n",
    "\n",
    "One advantage of using regression models when dealing with independent variables is the ability to capture and interpret the relationships between variables in a more nuanced way. In regression, the coefficients associated with the independent variables indicate the strength and direction of the relationship with the dependent variable. \n",
    "\n",
    "For example, in linear regression, the coefficient for an independent variable tells you how much the dependent variable is expected to increase (or decrease) for each one-unit increase in that independent variable, holding all other variables constant. This allows for a richer understanding of the underlying relationships, and you can quantify how a change in one feature is likely to impact the target variable. \n",
    "\n",
    "In contrast, classification models with nominal features generally don't offer this level of interpretability regarding the magnitude of impact of each feature on the target variable. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72448294",
   "metadata": {},
   "source": [
    "#### Question 6: Advantages when using regular numerical values rather than one-hot encoding\n",
    "\n",
    "One advantage of using regular numerical values rather than one-hot encoding for regression models is the preservation of ordinal relationships between categories. In many cases, the ordinal nature of a feature (e.g., age groups, education levels, or ratings) carries meaningful information that can be useful for making predictions. By converting these to regular numerical values, the model can capture the inherent order in the data and possibly result in a more accurate and interpretable model.\n",
    "\n",
    "For example, encoding age groups ('25-34 years', '35-44 years', etc.) as ordinal numerical values (2, 3, etc.) allows the regression model to understand that '35-44 years' is a higher age group compared to '25-34 years'. This ordinal information is lost when using one-hot encoding, which treats each category as an independent feature.\n",
    "\n",
    "Moreover, using regular numerical values for ordinal features reduces the dimensionality of the dataset, making the model simpler, more interpretable, and less prone to overfitting compared to one-hot encoding, which increases the number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e1bffc",
   "metadata": {},
   "source": [
    "#### Question 7: Classification or Regression?\n",
    "\n",
    "In the context of predicting suicide rates, I would recommend using a regression model over a classifier for the following reasons:\n",
    "\n",
    "##### Why Regression:\n",
    "\n",
    "1. **Continuous Outcome**: Suicide rates are continuous variables, generally expressed as rates per 100,000 population. Regression is well-suited for predicting a continuous outcome.\n",
    "\n",
    "2. **Subtlety and Nuance**: Regression can capture the subtlety and nuance in how various factors contribute to suicide rates. The coefficients provide an interpretable way to understand the magnitude and direction of each feature's effect.\n",
    "\n",
    "3. **Predictive Flexibility**: Regression models can make predictions for combinations of feature values that may not have been present in the training data. This is useful for making predictions about specific subgroups or under specific conditions.\n",
    "\n",
    "4. **Ordinal Features**: If the dataset contains ordinal features (like age groups), regression models can effectively incorporate this ordinality, as opposed to classifiers that would treat each age group as an independent category.\n",
    "\n",
    "5. **Policy Implications**: Understanding the rate allows policymakers to gauge the severity of the issue and allocate resources accordingly. A classification model, which would simply categorize an instance as high or low risk, might not provide this level of detail.\n",
    "\n",
    "##### Honorable Mentions for the Classifier:\n",
    "\n",
    "1. **Interpretability**: Classifiers can be easier to interpret when the outcome has clearly defined categories (e.g., 'High Risk' vs 'Low Risk').\n",
    "\n",
    "2. **Imbalanced Data**: If the data shows extreme imbalances in suicide rates, classification might be more appropriate, as many classifiers have good techniques for handling class imbalance.\n",
    "\n",
    "3. **Decision Boundaries**: Classifiers can capture complex decision boundaries, which might be useful if the relationship between features and suicide rates is not linear or easily approximable by a regression function.\n",
    "\n",
    "##### Final Recommendation:\n",
    "\n",
    "Given the nature of the problem and the type of insights we're likely interested in, a regression model would be more appropriate for predicting suicide rates. It offers the granularity, interpretability, and predictive flexibility that are crucial for understanding a complex issue like this.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ef03bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en685621)",
   "language": "python",
   "name": "en685621"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
