{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "659e134d",
   "metadata": {},
   "source": [
    "#### Andrew Taylor\n",
    "#### EN705.601.83 Applied Machine Learning\n",
    "#### September 8, 2023\n",
    "\n",
    "### Homework #2 Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d62d0e",
   "metadata": {},
   "source": [
    "### Question #1: Classifiers\n",
    "\n",
    "Let's answer this question with some descriptions, then in another section I'll compare and contrast.\n",
    "\n",
    "#### Description of ML Techniques:\n",
    "\n",
    "**Perceptron:**\n",
    "The perceptron is one of the earliest and simplest artificial neural network architectures. It was introduced by Frank Rosenblatt in 1957. The perceptron consists of a single layer of neurons that make binary decisions. It takes a vector of inputs, multiplies them with its weights, sums the products, and then passes the sum through a step function (typically a unit step function) to produce an output of either 0 or 1.\n",
    "\n",
    "**Support Vector Machines (SVM):**\n",
    "SVM is a supervised machine learning algorithm used for classification or regression. Introduced in the 1990s, it works by finding the hyperplane that best divides a dataset into classes. The primary principle is to maximize the margin between the closest data points (support vectors) of two classes. SVMs can be linear or non-linear, depending on the kernel used.\n",
    "\n",
    "**Decision Tree:**\n",
    "A decision tree is a flowchart-like structure in which each internal node represents a feature(or attribute), each branch represents a decision rule, and each leaf node represents an outcome. The topmost node in a decision tree is known as the root node. It learns to partition based on the attribute value. Decision trees can be used for both classification and regression.\n",
    "\n",
    "**Random Forest:**\n",
    "Random Forest is an ensemble learning method that constructs a multitude of decision trees at training time and outputs the class that is the mode of the classes (classification) or mean prediction (regression) of the individual trees. It is particularly effective in avoiding overfitting by training on various subsets of the data and averaging the results.\n",
    "\n",
    "---\n",
    "\n",
    "#### Comparison and Contrast:\n",
    "\n",
    "1. **Nature**:\n",
    "   - *Perceptron:* Neural network-based.\n",
    "   - *SVM:* Margin-based classifier.\n",
    "   - *Decision Tree:* Rule-based.\n",
    "   - *Random Forest:* Ensemble of decision trees.\n",
    "\n",
    "2. **Model Complexity**:\n",
    "   - *Perceptron:* Simple with a single layer.\n",
    "   - *SVM:* Can be complex especially with non-linear kernels.\n",
    "   - *Decision Tree:* Complexity varies with depth and branching.\n",
    "   - *Random Forest:* More complex due to multiple trees.\n",
    "\n",
    "3. **Handling Non-linear Data**:\n",
    "   - *Perceptron:* Struggles with non-linearly separable data.\n",
    "   - *SVM:* Can handle non-linearity using kernels.\n",
    "   - *Decision Tree:* Can handle non-linear data inherently.\n",
    "   - *Random Forest:* Naturally handles non-linearity due to the ensemble nature.\n",
    "\n",
    "4. **Overfitting**:\n",
    "   - *Perceptron:* Prone to overfitting on non-linearly separable data.\n",
    "   - *SVM:* Less prone due to margin optimization, but choice of kernel and parameters matters.\n",
    "   - *Decision Tree:* Can easily overfit if not pruned.\n",
    "   - *Random Forest:* Reduces overfitting through ensemble learning.\n",
    "\n",
    "5. **Training Speed**:\n",
    "   - *Perceptron:* Fast as it is a simple model.\n",
    "   - *SVM:* Slower, especially for large datasets or with complex kernels.\n",
    "   - *Decision Tree:* Moderate, depends on the depth and branching.\n",
    "   - *Random Forest:* Slower due to multiple trees, but can be parallelized.\n",
    "\n",
    "6. **Interpretability**:\n",
    "   - *Perceptron:* Moderately interpretable due to weights.\n",
    "   - *SVM:* Less interpretable, especially with non-linear kernels.\n",
    "   - *Decision Tree:* Highly interpretable as rules can be visualized.\n",
    "   - *Random Forest:* Less interpretable than a single decision tree but provides feature importance.\n",
    "\n",
    "---\n",
    "\n",
    "Now let's answer the specific questions:\n",
    "\n",
    "---\n",
    "\n",
    "**Optimization Problem and Cost Function:**\n",
    "\n",
    "1. **Perceptron:**\n",
    "   - **Optimization Problem:** Yes.\n",
    "   - **Cost Function:** Perceptron uses a simple misclassification rate. The algorithm tries to minimize the number of misclassified samples.\n",
    "   \n",
    "2. **Support Vector Machines (SVM):**\n",
    "   - **Optimization Problem:** Yes.\n",
    "   - **Cost Function:** SVM minimizes the hinge loss subject to margin constraints. The objective is to maximize the margin between the two classes.\n",
    "   \n",
    "3. **Decision Tree:**\n",
    "   - **Optimization Problem:** Yes.\n",
    "   - **Cost Function:** Decision trees don't have a traditional cost function like the above models. Instead, they use metrics like entropy, Gini impurity, or classification error to decide on splits.\n",
    "   \n",
    "4. **Random Forest:**\n",
    "   - **Optimization Problem:** Yes, but at the individual tree level.\n",
    "   - **Cost Function:** Like decision trees, random forests use metrics like entropy or Gini impurity for their individual trees.\n",
    "\n",
    "---\n",
    "\n",
    "**Speed, Strength, Robustness, and Statistical considerations:**\n",
    "\n",
    "1. **Perceptron:**\n",
    "   - **Speed:** Fast.\n",
    "   - **Strength:** Good for linearly separable data.\n",
    "   - **Robustness:** Sensitive to noisy data and outliers.\n",
    "   - **Statistical:** Prone to overfitting on non-linearly separable data.\n",
    "   \n",
    "2. **SVM:**\n",
    "   - **Speed:** Moderate to slow, depending on kernel and dataset size.\n",
    "   - **Strength:** Effective for both linear and certain non-linear patterns.\n",
    "   - **Robustness:** Robust against overfitting, especially in high-dimensional space.\n",
    "   - **Statistical:** Effective, but can be sensitive to the choice of kernel and parameters.\n",
    "   \n",
    "3. **Decision Tree:**\n",
    "   - **Speed:** Fast to moderate.\n",
    "   - **Strength:** Can capture non-linear relationships.\n",
    "   - **Robustness:** Prone to overfitting if not pruned.\n",
    "   - **Statistical:** Can be unstable, small changes in data can lead to different trees.\n",
    "   \n",
    "4. **Random Forest:**\n",
    "   - **Speed:** Slower due to multiple trees, but can be parallelized.\n",
    "   - **Strength:** Can capture complex patterns and relationships.\n",
    "   - **Robustness:** More robust against overfitting compared to individual decision trees.\n",
    "   - **Statistical:** Provides a measure of feature importance and reduces variance.\n",
    "\n",
    "---\n",
    "\n",
    "**Feature Type Classifier Naturally Uses:**\n",
    "\n",
    "1. **Perceptron:**\n",
    "   - Linear combinations of features.\n",
    "   \n",
    "2. **SVM:**\n",
    "   - Linear or non-linear transformations based on kernels.\n",
    "   \n",
    "3. **Decision Tree:**\n",
    "   - Uses features directly to make decisions based on entropy, Gini impurity, or classification error.\n",
    "   \n",
    "4. **Random Forest:**\n",
    "   - Uses features directly like decision trees but across multiple trees.\n",
    "\n",
    "---\n",
    "\n",
    "**Which One to Try First on a Dataset?**\n",
    "\n",
    "The choice of which model to try first on a dataset depends on the nature and size of the dataset, as well as the specific problem at hand. However, as a general guideline:\n",
    "\n",
    "- For linearly separable data, starting with a perceptron or linear SVM can be a good choice.\n",
    "- For datasets with complex non-linear patterns but not too large in size, SVM with non-linear kernels can be effective.\n",
    "- Decision trees can be a good starting point due to their interpretability and ability to handle non-linear data.\n",
    "- Random Forest is often a good default choice for many datasets due to its robustness and ability to handle both linear and non-linear patterns.\n",
    "\n",
    "---\n",
    "\n",
    "In conclusion, the ideal model often varies with the nature of the data and problem. It's beneficial to start with a simpler model to establish a baseline and then explore more complex models as needed."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a984e325",
   "metadata": {},
   "source": [
    "### Question #2: Definitions of Feature Types\n",
    "\n",
    "##### 1. Numerical\n",
    "**Definition:** Numerical features represent measurable quantities and can take any value within a range. They can be further divided into continuous (can take any value in a range) and discrete (can only take certain specific values).\n",
    "\n",
    "**Example from Iris dataset:** \n",
    "- sepal length: This is a continuous numerical feature as it can take any value within a range to represent the length of the sepal in centimeters.\n",
    "\n",
    "##### 2. Nominal\n",
    "**Definition:** Nominal features are categorical features that donâ€™t have a natural order or ranking. They can take two or more categories, but there's no intrinsic ordering to the categories.\n",
    "\n",
    "**Example from Iris dataset:** \n",
    "- species: This is a nominal feature as it can take values like \"setosa\", \"versicolor\", or \"virginica\". There's no inherent order to these species names.\n",
    "\n",
    "##### 3. Date\n",
    "**Definition:** Date features represent specific days, months, years, or even timestamps. They can be used to track the progression of time.\n",
    "\n",
    "**Example from a Air Quality dataset:** \n",
    "- **Air Quality Dataset**: This dataset contains daily readings of the air quality values from 2004 to 2005. A feature like Date in this dataset would indicate the specific day when the air quality was recorded.\n",
    "\n",
    "##### 4. Text\n",
    "**Definition:** Text features consist of words, sentences, or paragraphs. These are typically unstructured and require special preprocessing techniques to extract meaningful information.\n",
    "\n",
    "**Example from Newsgroups dataset:** \n",
    "- **20 Newsgroups**: This is a dataset for text classification, containing newsgroup documents, organized into 20 different newsgroups. Each document is a collection of text, representing the content of a post or an article.\n",
    "\n",
    "##### 5. Image\n",
    "**Definition:** Image features are typically represented as matrices of pixel values. Each pixel can have one (for grayscale images) or multiple values (for color images).\n",
    "\n",
    "**Example from a CIFAR-10 dataset:** \n",
    "- **CIFAR-10**: This dataset consists of 60,000 32x32 color images in 10 different classes, representing objects like 'airplane', 'automobile', 'bird', etc. Each image is represented as a 3-dimensional array of pixel values (32x32 pixels and 3 channels for RGB).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e803e906",
   "metadata": {},
   "source": [
    "### Question 3 - Performance Metrics\n",
    "\n",
    "Here's some of the common machine learning classifier performance metrics:\n",
    "\n",
    "1. **Accuracy**:\n",
    "   - **Definition**: It measures the proportion of correctly predicted classification assignments among the total instances in the dataset.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Accuracy} = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions made}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - No specific jargon used in this definition.  \n",
    "\n",
    "2. **Precision**:\n",
    "   - **Definition**: Precision measures the proportion of correctly predicted positive instances out of all instances that were predicted as positive.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Precision} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - **True Positives (TP)**: Number of positive instances correctly predicted as positive.\n",
    "     - **False Positives (FP)**: Number of negative instances wrongly predicted as positive.  \n",
    "\n",
    "3. **Recall (or Sensitivity)**:\n",
    "   - **Definition**: Recall measures the proportion of correctly predicted positive instances out of all actual positive instances.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Recall} = \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - **False Negatives (FN)**: Number of positive instances wrongly predicted as negative.  \n",
    "\n",
    "4. **F1-Score**:\n",
    "   - **Definition**: It is the harmonic mean of precision and recall, providing a balance between the two when there's an uneven class distribution.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     F1 = 2 \\times \\frac{\\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "     $$\n",
    "   - **Jargon**: \n",
    "     - No additional jargon apart from precision and recall.  \n",
    "\n",
    "5. **Specificity**:\n",
    "   - **Definition**: Measures the proportion of correctly predicted negative instances out of all actual negative instances.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Specificity} = \\frac{\\text{True Negatives}}{\\text{True Negatives} + \\text{False Positives}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - **True Negatives (TN)**: Number of negative instances correctly predicted as negative.  \n",
    "\n",
    "6. **Area Under the Receiver Operating Characteristic Curve (AUC-ROC)**:\n",
    "   - **Definition**: AUC-ROC represents the likelihood of the model distinguishing between a randomly chosen positive instance and a randomly chosen negative instance. ROC is a probability curve, and AUC represents the degree or measure of separability.\n",
    "   - **Formula**: AUC-ROC doesn't have a simple formula; it's computed by plotting True Positive Rate (Recall) vs False Positive Rate at various threshold settings and computing the area under this curve.\n",
    "   - **Jargon**:\n",
    "     - **True Positive Rate (TPR)**: Same as Recall.\n",
    "     - **False Positive Rate (FPR)**:  $$\\frac{\\text{False Positives}}{\\text{False Positives} + \\text{True Negatives}}$$.  \n",
    "\n",
    "7. **Area Under the Precision-Recall Curve (AUC-PR)**:\n",
    "   - **Definition**: Similar to AUC-ROC, but it focuses on the performance of a classifier on the positive (minority) class. It's useful when the classes are imbalanced.\n",
    "   - **Formula**: It's computed by plotting Precision vs Recall at various threshold settings and computing the area under this curve.\n",
    "   - **Jargon**: No additional jargon apart from precision and recall.  \n",
    "\n",
    "8. **Logarithmic Loss (Log Loss)**:\n",
    "   - **Definition**: Measures the performance of a classification model where the prediction is a probability value between 0 and 1. Lower log loss indicates better performance.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Log Loss} = -\\frac{1}{N} \\sum_{i=1}^{N} [y_i \\log(p_i) + (1 - y_i) \\log(1 - p_i)]\n",
    "     $$\n",
    "     Where ' N ' is the number of samples, ' y_i ' is the actual class (0 or 1), and ' p_i ' is the predicted probability of the instance belonging to class 1.\n",
    "   - **Jargon**:\n",
    "     -  y_i : Actual class label (0 or 1). \n",
    "     -  p_i : Predicted probability of the instance being in class 1.   \n",
    "\n",
    "9. **Matthews Correlation Coefficient (MCC)**:\n",
    "   - **Definition**: It is a measure of the quality of binary classifications. It returns a value between -1 and 1. A coefficient of +1 represents a perfect prediction, 0 no better than random prediction, and -1 indicates total disagreement between prediction and observation.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     MCC = \\frac{(TP \\times TN) - (FP \\times FN)}{\\sqrt{(TP+FP)(TP+FN)(TN+FP)(TN+FN)}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - We've already defined TP, TN, FP, FN in the previous metrics.  \n",
    "\n",
    "10. **Cohen's Kappa**:\n",
    "   - **Definition**: It measures the agreement between two raters (in this context, the actual and the predicted labels). It considers the agreement occurring by chance. A Kappa of 1 indicates perfect agreement, while a Kappa of 0 indicates agreement equivalent to chance.\n",
    "   - **Formula**: It's a bit more complex as it involves computing expected and observed agreement. The basic formula is:\n",
    "     $$\n",
    "     Kappa = \\frac{P_o - P_e}{1 - P_e}\n",
    "     $$\n",
    "     Where ' P_o ' is the observed agreement, and ' P_e ' is the expected agreement.\n",
    "   - **Jargon**:\n",
    "     - P_o : Observed agreement. \n",
    "     - P_e : Expected agreement.   \n",
    "\n",
    "11. **Balanced Accuracy**:\n",
    "   - **Definition**: It calculates the arithmetic mean of sensitivity (recall) and specificity. It's especially useful for imbalanced datasets.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Balanced Accuracy} = \\frac{\\text{Sensitivity} + \\text{Specificity}}{2}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - Sensitivity and Specificity were defined previously.  \n",
    "\n",
    "12. **Hamming Loss**:\n",
    "   - **Definition**: It is used for multilabel classification and represents the fraction of labels that are incorrectly predicted.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Hamming Loss} = \\frac{1}{N} \\sum_{i=1}^{N} \\text{xor}(y_i, \\hat{y}_i)\n",
    "     $$\n",
    "     Where ' N ' is the number of samples, ' y_i ' is the actual label set, and $ \\hat{y}_i $' is the predicted label set.   \n",
    "   \n",
    "   - **Jargon**:\n",
    "     - $ \\text{xor} $: Bitwise exclusive or operation.  \n",
    "\n",
    "13. **Zero-One Loss**:\n",
    "   - **Definition**: It represents the number of misclassifications. It's often normalized to be between 0 and 1, with 0 being a perfect classifier.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Zero-One Loss} = \\frac{\\text{Number of misclassifications}}{\\text{Total number of predictions}}\n",
    "     $$\n",
    "   - **Jargon**:\n",
    "     - No specific jargon used in this definition.  \n",
    "\n",
    "14. **Brier Score**:\n",
    "   - **Definition**: Measures the mean squared difference between predicted probabilities and the actual outcomes. It's appropriate for binary classification tasks.\n",
    "   - **Formula**:\n",
    "     $$\n",
    "     \\text{Brier Score} = \\frac{1}{N} \\sum_{i=1}^{N} (p_i - o_i)^2\n",
    "     $$\n",
    "     Where ' N ' is the number of samples, ' p_i ' is the predicted probability, and ' o_i ' is the actual outcome (0 or 1).\n",
    "   - **Jargon**:\n",
    "     - *o_i*: Actual outcome for the i-th sample (either 0 or 1).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c054ea7",
   "metadata": {},
   "source": [
    "### Question 4: Correlation Program\n",
    "\n",
    "The formula for correlation between two variables  X and  Y is:\n",
    "\n",
    "$$\n",
    "r_{XY} = \\frac{\\sum_{i=1}^{n} (X_i - \\bar{X})(Y_i - \\bar{Y})}{\\sqrt{\\sum_{i=1}^{n} (X_i - \\bar{X})^2 \\sum_{i=1}^{n} (Y_i - \\bar{Y})^2}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- r_{XY} is the correlation coefficient between X and Y  \n",
    "- X_i and Y_i are individual data points  \n",
    "- $ \\bar{X}  and  \\bar{Y} $ are means of X and Y respectively  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4abb3ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual Correlation Matrix:\n",
      "[1.0, 0.827200403531722, 0.6353762113239018, 0.6134976734624114, 0.5246793925817081, 0.8258779536403567, 0.5633981217777579, 0.8103506354632608]\n",
      "[0.827200403531722, 1.0, 0.6497991951468062, 0.6444103878875822, 0.5415632950080242, 0.8105735363036228, 0.46701206060973394, 0.7922276143050834]\n",
      "[0.6353762113239018, 0.6497991951468062, 1.0, 0.7280235718785817, 0.6086507072838143, 0.705254345086195, 0.4270474518133488, 0.6901323687886892]\n",
      "[0.6134976734624114, 0.6444103878875822, 0.7280235718785817, 1.0, 0.663706852514935, 0.7121543243652508, 0.40811584579179266, 0.6841365241316726]\n",
      "[0.5246793925817081, 0.5415632950080242, 0.6086507072838143, 0.663706852514935, 1.0, 0.6374692057544721, 0.3725256035105942, 0.6453645135280112]\n",
      "[0.8258779536403567, 0.8105735363036228, 0.705254345086195, 0.7121543243652508, 0.6374692057544721, 1.0, 0.501311000534699, 0.8824125749045746]\n",
      "[0.5633981217777579, 0.46701206060973394, 0.4270474518133488, 0.40811584579179266, 0.3725256035105942, 0.501311000534699, 1.0, 0.5458710294711385]\n",
      "[0.8103506354632608, 0.7922276143050834, 0.6901323687886892, 0.6841365241316726, 0.6453645135280112, 0.8824125749045746, 0.5458710294711385, 1.0]\n",
      "\n",
      "DataFrame.corr() Matrix:\n",
      "                   GRE Score  TOEFL Score  University Rating       SOP  \\\n",
      "GRE Score           1.000000     0.827200           0.635376  0.613498   \n",
      "TOEFL Score         0.827200     1.000000           0.649799  0.644410   \n",
      "University Rating   0.635376     0.649799           1.000000  0.728024   \n",
      "SOP                 0.613498     0.644410           0.728024  1.000000   \n",
      "LOR                 0.524679     0.541563           0.608651  0.663707   \n",
      "CGPA                0.825878     0.810574           0.705254  0.712154   \n",
      "Research            0.563398     0.467012           0.427047  0.408116   \n",
      "Chance of Admit     0.810351     0.792228           0.690132  0.684137   \n",
      "\n",
      "                       LOR       CGPA  Research  Chance of Admit   \n",
      "GRE Score          0.524679  0.825878  0.563398          0.810351  \n",
      "TOEFL Score        0.541563  0.810574  0.467012          0.792228  \n",
      "University Rating  0.608651  0.705254  0.427047          0.690132  \n",
      "SOP                0.663707  0.712154  0.408116          0.684137  \n",
      "LOR                1.000000  0.637469  0.372526          0.645365  \n",
      "CGPA               0.637469  1.000000  0.501311          0.882413  \n",
      "Research           0.372526  0.501311  1.000000          0.545871  \n",
      "Chance of Admit    0.645365  0.882413  0.545871          1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Question 4 Correlation Program from Scratch not using Numpy\n",
    "\n",
    "import math\n",
    "\n",
    "# Load the dataset using built-in Python functions.\n",
    "with open(\"Admission_Predict_Ver1.1.csv\", \"r\") as file:\n",
    "    lines = file.readlines()\n",
    "    header = lines[0].strip().split(\",\")\n",
    "    data = [list(map(float, line.strip().split(\",\"))) for line in lines[1:]]\n",
    "\n",
    "# Extract the relevant columns.\n",
    "columns = [row[1:9] for row in data]  # Extracting columns 2 to 9 (0-indexed).\n",
    "\n",
    "# Define a function to compute the mean.\n",
    "def mean(column):\n",
    "    return sum(column) / len(column)\n",
    "\n",
    "# Define a function to extract a specific column from the data.\n",
    "def extract_column(data, col_idx):\n",
    "    return [row[col_idx] for row in data]\n",
    "\n",
    "# Define a function to compute the correlation coefficient between two columns.\n",
    "def correlation(col1, col2):\n",
    "    mean1, mean2 = mean(col1), mean(col2)\n",
    "    numerator = sum([(col1[i] - mean1) * (col2[i] - mean2) for i in range(len(col1))])\n",
    "    denominator = (sum([(col1[i] - mean1) ** 2 for i in range(len(col1))]) * \n",
    "                   sum([(col2[i] - mean2) ** 2 for i in range(len(col2))])) ** 0.5\n",
    "    \n",
    "    # Handle zero variance case\n",
    "    if math.isclose(denominator, 0):\n",
    "        return float('nan')\n",
    "    \n",
    "    return numerator / denominator\n",
    "\n",
    "# Create the correlation matrix.\n",
    "num_cols_corrected = len(columns[0])\n",
    "\n",
    "# Recreate the correlation matrix using the num_cols value.\n",
    "correlation_matrix_corrected = [\n",
    "    [correlation(extract_column(columns, i), extract_column(columns, j)) \n",
    "     for j in range(num_cols_corrected)] \n",
    "    for i in range(num_cols_corrected)]\n",
    "\n",
    "# Display the corrected manually computed correlation matrix.\n",
    "print(\"Manual Correlation Matrix:\")\n",
    "for row in correlation_matrix_corrected:\n",
    "    print(row)\n",
    "\n",
    "\n",
    "# For verification using pandas:\n",
    "import pandas as pd\n",
    "\n",
    "data_df = pd.read_csv(\"Admission_Predict_Ver1.1.csv\")\n",
    "subset_data_df = data_df.iloc[:, 1:9]\n",
    "correlation_matrix_df = subset_data_df.corr()\n",
    "\n",
    "print(\"\\nDataFrame.corr() Matrix:\")\n",
    "print(correlation_matrix_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d31726",
   "metadata": {},
   "source": [
    "1. **Should we use 'Serial no'?**\n",
    "   - The 'Serial no' is typically a unique identifier for each row or observation in the dataset. From a data analysis or modeling perspective, it does not carry any meaningful information about the variables of interest. Including it in the analysis or model could introduce noise without providing any genuine insights or predictive power. Therefore, it's recommended not to use 'Serial no' for analysis or modeling purposes.\n",
    "\n",
    "2. **Observe that the diagonal of this matrix should have all 1's and explain why?**\n",
    "   - The diagonal of the correlation matrix contains the correlation of each variable with itself. The Pearson correlation coefficient of a variable with itself is always 1. This is because the correlation coefficient measures the linear relationship between two variables, and a variable is perfectly linearly related to itself. Mathematically, the numerator and the denominator of the correlation formula will be identical when correlating a variable with itself, resulting in a value of 1.\n",
    "\n",
    "3. **Since the last column can be used as the target (dependent) variable, what do you think about the correlations between all the variables?**\n",
    "   - Observing the last column (or row, since the matrix is symmetric) gives the correlation values of each variable with the 'Chance of Admit' (our potential target variable).\n",
    "   - Most of the variables have a high positive correlation with the 'Chance of Admit'. This suggests that as these variables increase, the chance of admission typically increases, and vice versa.\n",
    "   - The variable with the highest positive correlation to the 'Chance of Admit' (excluding the 1 on the diagonal) is the one that is most linearly related to the chances of admission.\n",
    "   - It's worth noting that even if variables are correlated with the target variable, it doesn't necessarily imply causation. It simply means there's a linear association.\n",
    "\n",
    "4. **Which variable should be the most important for prediction of 'Chance of Admit'?**\n",
    "   - The importance of a variable in predicting the 'Chance of Admit' can be initially gauged by its correlation magnitude with the 'Chance of Admit'. The variable with the highest absolute correlation value (closest to 1 or -1) would be the most linearly related to the 'Chance of Admit'.\n",
    "   - From the computed correlation matrix, the variable that has the highest correlation with the 'Chance of Admit' (apart from itself) is the one at the 6th position (0-indexed), which corresponds to the 'CGPA' based on the structure of the dataset. This suggests that 'CGPA' might be the most important variable for predicting the 'Chance of Admit'.\n",
    "   - However, it's essential to understand that correlation only captures linear relationships. There might be other non-linear associations or interactions between variables that can also be important. Advanced modeling techniques can further elucidate the importance and contribution of each variable to the prediction.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (en685621)",
   "language": "python",
   "name": "en685621"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
