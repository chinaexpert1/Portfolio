{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <h3 align=\"center\"> __Johns Hopkins University__</h3>\n",
    "## <h3 align=\"center\">__Whiting School of Engineering__</h3>\n",
    "## <h3 align=\"center\">__Engineering for Professionals__</h3>\n",
    "## <h3 align=\"center\">__685.621 Algorithms for Data Science__</h3>\n",
    "## <h3 align=\"center\">__Homework 5__</h3>\n",
    "## <h3 align=\"center\">__Assigned at the start of Module 12__</h3>\n",
    "## <h3 align=\"center\">__Due at the end of Module 13__</h3><br>\n",
    "## <h3 align=\"center\">__Total Points 100/100__</h3>\n",
    "Class, the below is a standard set of instructions for each HW, in this assignment groups will be set up for collaboration.<br><br>\n",
    "Make sure your group starts one thread for the collaborative problems. You are required to participate in the collaborative problem and subproblem separately. Please do not directly post a complete\n",
    "solution, the goal is for the group to develop a solution after everyone has participated. Please ensure\n",
    "you have a write-up with solutions to each problem and subproblems, you are also required to submit\n",
    "code that will be compiled when grading the assignment. In each of the problems you are allowed to\n",
    "use built-in functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __1 - Module 13 Note this is Collaborative Problem - Note: create threads for both subparts, you are required to participate in both subparts.__<br>\n",
    "*30 Points Total*<br><br>\n",
    "In this problem you will use a built-in Convolutional Neural Network (CNN) using either the Iris or numerical (MNIST) data sets and show the classification accuracy:<br><br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "\n",
    "# load dataset\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "# Load the dataset\n",
    "dataset = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "# Split dataset into input (X) and output (y) variables\n",
    "X = dataset.iloc[:, 0:4].values\n",
    "y = dataset.iloc[:, 4].values\n",
    "\n",
    "# Normalize features\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "# Encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "encoded_Y = encoder.transform(y)\n",
    "\n",
    "# Convert integers to one-hot encoding using a custom function\n",
    "def to_categorical(y, num_classes=None):\n",
    "    \"\"\"Converts a class vector (integers) to binary class matrix.\"\"\"\n",
    "    y = np.array(y, dtype='int')\n",
    "    input_shape = y.shape\n",
    "    if input_shape and input_shape[-1] == 1 and len(input_shape) > 1:\n",
    "        input_shape = tuple(input_shape[:-1])\n",
    "    y = y.ravel()\n",
    "    if not num_classes:\n",
    "        num_classes = np.max(y) + 1\n",
    "    n = y.shape[0]\n",
    "    categorical = np.zeros((n, num_classes))\n",
    "    categorical[np.arange(n), y] = 1\n",
    "    output_shape = input_shape + (num_classes,)\n",
    "    categorical = np.reshape(categorical, output_shape)\n",
    "    return categorical\n",
    "\n",
    "y = to_categorical(encoded_Y)\n",
    "\n",
    "# Reshape the data to fit into a CNN. \n",
    "# Since we have 4 features, we'll treat each sample as a 1D \"image\" of size 4x1\n",
    "X = X.reshape(X.shape[0], 4, 1)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_12312/1330886536.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m## Type the code for part 1 here ##\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mDense\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mConv1D\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFlatten\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\en685621\\lib\\site-packages\\keras\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     19\u001b[0m \"\"\"\n\u001b[0;32m     20\u001b[0m \u001b[1;31m# pylint: disable=unused-import\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtf2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdistribute\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "## Type the code for part 1 here ##\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv1D, Flatten\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Conv1D(filters=32, kernel_size=2, activation='relu', input_shape=(4, 1)))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(50, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=50, batch_size=10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type the code for part 2 here ##\n",
    "from sklearn.metrics import classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Predict the values\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "y_true_classes = np.argmax(y_test, axis=1)\n",
    "\n",
    "# Print classification report\n",
    "print(classification_report(y_true_classes, y_pred_classes, target_names=encoder.classes_))\n",
    "\n",
    "# Print accuracy\n",
    "accuracy = (y_pred_classes == y_true_classes).mean()\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# __2 - Module 12 Optimization - Note this is a Collaborative Problem  __<br>\n",
    "70 points total\n",
    "\n",
    "In this problem, you will develop the Support Vector Machine (SVM) algorithm from scratch to classify the Iris data set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [15 points] Using the SVM in the Optimization course notes, develop psuedocode for an SVM classifier using a linear and separately an rbf kernel.<br><br>\n",
    "2. [Optional] no need to discuss collaboratively - Analyze the runtime of your design in big O notation and calculate a total runtime such that each line of psuedocode is accounted for.<br><br>\n",
    "3. [55 points] Implement your SVM using Python:<br><br>\n",
    "    - Train three two class models using the Iris dataset as input training data, the Iris data will need to be reconfigured as a one vs. all or one vs. one data set.\n",
    "    - Process the test data set to determine which class each test observation belongs to, in this problem you will simply use all 150 observations as your test data.\n",
    "    - What is the classification accuracy of your design?\n",
    "    - Is there a difference in performance between the two kernels? Why do you think that is?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type the response for part 1 here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type the response for optional part 2 here ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Type the code for part 3 here ##"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Type your response for part 3 here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References<br><br>\n",
    "[1] Charu C. Aggarwal, Neural Networks and Deep Learning, Springer 2018<br><br>\n",
    "[2] Ahmad Abdolsaheb, How to make your Tic Tac Toe game unbeatable by using the minimax algorithm,\n",
    "2020, https://www.freecodecamp.org/news/how-to-make-your-tic-tac-toe-game-unbeatable-byusing-\n",
    "the-minimax-algorithm-9d690bad4b37/<br><br>\n",
    "[3] Francois Chollet, Deep Learning with Python, Manning, 2018<br><br>\n",
    "[4] Stephen Cook, The Complexity of Theorem Proving Procedures, Proceedings of the third annual ACM symposium<br><br>\n",
    "on Theory of computing, pp. 151-158, 1971\n",
    "[5] Ian Goodfellow, Yoshua Bengio and Aaron Courville, Deep Learning, MIT Press, 2016,\n",
    "https://www.deeplearningbook.org/<br><br>\n",
    "[6] Patric Honner (Contributing Columnist), Why Winning in Rock-Paper-Scissors (and in Life) Isn’t Everything,\n",
    "What does John Nash’s game theory equilibrium concept look like in Rock-Paper-Scissors?, an article in the\n",
    "online Quanta Magazine, April 2, 2018, https://www.quantamagazine.org/the-game-theory-math-behindrock-\n",
    "paper-scissors-20180402/<br><br>\n",
    "[7] Richard M. Karp, Reducibility Among Combinatorial Problems, In R. E. Miller and J. W. Thatcher (editors),\n",
    "Complexity of Computer Computations, New York: Plenum, pp. 85-103, 1972<br><br>\n",
    "[8] Stephen G. Nash and Ariela Sofer, Linear and Nonlinear Programming, McGraw-Hill, 1996<br><br>\n",
    "[9] Stuart Russell and Peter Norvig, Arti cial Intelligence a Modern Approach Fourth Edition, Pearson, 2020<br><br>\n",
    "[10] Sergios Theodoridis and Konstantinos Koutroumbas, Pattern Recognition Third Edition, San Diego, CA:\n",
    "Academic Press, 2006<br><br>\n",
    "[11] Thomas H. Cormen, Charles E. Leiserson, Ronal L. Rivest and Cli ord Stein, Introduction to Algorithms,\n",
    "3rd Edition, MIT Press, 2009<br><br>\n",
    "[12] David Zuckerman, NP-Complete Problems Have a Version That’s Hard to Approximate, IEEE, Proceedings\n",
    "of the Eighth Annual Structure in Complexity Theory Conference, pp. 305-312, 1993<br><br>\n",
    "[13] David Zuckerman, On Unapproximable Versions of NP-Complete Problems, SIAM Journal on Computing,\n",
    "Volume 25, Issue 6, pp. 1293-1304, 1996"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  },
  "kernelspec": {
   "display_name": "Python (en685621)",
   "language": "python",
   "name": "en685621"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
